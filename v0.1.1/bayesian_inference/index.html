<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian Inference · QuantumMeasurements.jl</title><meta name="title" content="Bayesian Inference · QuantumMeasurements.jl"/><meta property="og:title" content="Bayesian Inference · QuantumMeasurements.jl"/><meta property="twitter:title" content="Bayesian Inference · QuantumMeasurements.jl"/><meta name="description" content="Documentation for QuantumMeasurements.jl."/><meta property="og:description" content="Documentation for QuantumMeasurements.jl."/><meta property="twitter:description" content="Documentation for QuantumMeasurements.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="QuantumMeasurements.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">QuantumMeasurements.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../quick_start/">Quick-Start</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../twin_photons_pvm/">Twin Photons</a></li><li><a class="tocitem" href="../twin_photons_prop/">Twin photons with proportional measurement</a></li><li><a class="tocitem" href="../spatial_structure/">Spatial structure of light</a></li><li><a class="tocitem" href="../obstructed_spatial_structure/">Spatial structure of light with obstructions</a></li></ul></li><li><span class="tocitem">Theory</span><ul><li><a class="tocitem" href="../random_states/">Random State Generation</a></li><li><a class="tocitem" href="../mathematical_foundations/">Mathematical Foundations</a></li><li><a class="tocitem" href="../maximum_likelihood/">Maximum Likelihood Estimation</a></li><li class="is-active"><a class="tocitem" href>Bayesian Inference</a><ul class="internal"><li><a class="tocitem" href="#Theory-and-Motivation"><span>Theory and Motivation</span></a></li><li><a class="tocitem" href="#The-Prior-Distribution"><span>The Prior Distribution</span></a></li><li><a class="tocitem" href="#Key-Properties"><span>Key Properties</span></a></li><li><a class="tocitem" href="#Implementation:-MALA-Algorithm"><span>Implementation: MALA Algorithm</span></a></li><li><a class="tocitem" href="#Computational-Cost"><span>Computational Cost</span></a></li><li><a class="tocitem" href="#Usage"><span>Usage</span></a></li><li><a class="tocitem" href="#When-to-Use-Bayesian-Inference"><span>When to Use Bayesian Inference</span></a></li><li><a class="tocitem" href="#Relationship-to-Other-Methods"><span>Relationship to Other Methods</span></a></li><li><a class="tocitem" href="#See-Also"><span>See Also</span></a></li></ul></li><li><a class="tocitem" href="../proportional_measurements/">Proportional Measurements</a></li></ul></li><li><span class="tocitem">How-to Guides</span><ul><li><a class="tocitem" href="../choosing_methods/">Choosing Estimation Methods</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Theory</a></li><li class="is-active"><a href>Bayesian Inference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian Inference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/marcsgil/QuantumMeasurements.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/marcsgil/QuantumMeasurements.jl/blob/master/docs/src/bayesian_inference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Bayesian-Inference"><a class="docs-heading-anchor" href="#Bayesian-Inference">Bayesian Inference</a><a id="Bayesian-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Inference" title="Permalink"></a></h1><p>Bayesian inference addresses limitations of both linear inversion and maximum likelihood estimation. While linear inversion can produce unphysical states and MLE yields point estimates without uncertainty quantification, Bayesian methods provide posterior distributions that incorporate uncertainty and prior knowledge.</p><h2 id="Theory-and-Motivation"><a class="docs-heading-anchor" href="#Theory-and-Motivation">Theory and Motivation</a><a id="Theory-and-Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Theory-and-Motivation" title="Permalink"></a></h2><p>Bayesian Mean Estimation (BME) computes a posterior distribution over all possible states and reports the posterior mean as the estimate [<a href="../references/#Blume-Kohout_2010">4</a>]:</p><p class="math-container">\[\hat{\rho}_{\text{BME}} = \int \rho \, \pi(\rho | \mathcal{D}) \, d\rho\]</p><p>where <span>$\pi(\rho | \mathcal{D})$</span> is the posterior distribution given data <span>$\mathcal{D}$</span>. According to Bayes&#39; rule:</p><p class="math-container">\[\pi(\rho | \mathcal{D}) = \frac{\mathcal{L}(\mathcal{D} | \rho) \pi_0(\rho)}{\mathcal{Z}}\]</p><p>Here, <span>$\mathcal{L}(\mathcal{D} | \rho)$</span> is the likelihood function, <span>$\pi_0(\rho)$</span> is the prior distribution, and <span>$\mathcal{Z}$</span> is the normalization constant.</p><h2 id="The-Prior-Distribution"><a class="docs-heading-anchor" href="#The-Prior-Distribution">The Prior Distribution</a><a id="The-Prior-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#The-Prior-Distribution" title="Permalink"></a></h2><p>The choice of prior <span>$\pi_0(\rho)$</span> is both a strength and limitation of Bayesian inference. The prior encodes assumptions about the quantum state before observing data, which can be valuable when genuine prior knowledge exists (e.g., from physical constraints or previous experiments).</p><p><strong>Default Choice</strong>: The package uses a uniform prior in the Bloch vector representation by default (<code>log_prior=θ -&gt; zero(...)</code>), which corresponds to a flat distribution over the traceless part of the density matrix. This choice is uninformative and lets the data dominate the posterior.</p><p><strong>Arbitrariness Concern</strong>: The prior choice is inherently subjective and can influence results, particularly with limited data. Different reasonable priors may yield different estimates. However, as the amount of data increases, the prior&#39;s influence diminishes and the posterior concentrates around the maximum likelihood estimate.</p><p><strong>Robustness</strong>: For informationally complete measurements with sufficient data, Bayesian estimates become relatively insensitive to prior choice. The likelihood function dominates the posterior, making the method practically robust despite the theoretical arbitrariness.</p><h2 id="Key-Properties"><a class="docs-heading-anchor" href="#Key-Properties">Key Properties</a><a id="Key-Properties-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Properties" title="Permalink"></a></h2><p><strong>Full-Rank States</strong>: BME never produces zero eigenvalues. The posterior mean incorporates uncertainty, ensuring all eigenvalues remain positive for reasonable priors.</p><p><strong>Uncertainty Quantification</strong>: The posterior covariance matrix provides error bars. Each parameter&#39;s uncertainty can be computed from the posterior distribution.</p><p><strong>Optimal Performance</strong>: Under proper scoring rules, BME minimizes the expected loss for operationally meaningful distance measures between quantum states.</p><p><strong>Small Sample Performance</strong>: BME handles limited datasets by incorporating prior knowledge and regularization through posterior averaging.</p><h2 id="Implementation:-MALA-Algorithm"><a class="docs-heading-anchor" href="#Implementation:-MALA-Algorithm">Implementation: MALA Algorithm</a><a id="Implementation:-MALA-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation:-MALA-Algorithm" title="Permalink"></a></h2><p>The package implements Bayesian inference using the Metropolis-Adjusted Langevin Algorithm (MALA), an MCMC method that samples from the posterior distribution.</p><p>MALA proposes new states using the gradient of the log-posterior:</p><p class="math-container">\[\theta_{\text{prop}} = \theta_{\text{current}} + \frac{\sigma^2}{2} \nabla \log \pi(\theta_{\text{current}} | \mathcal{D}) + \sigma \epsilon\]</p><p>where <span>$\epsilon \sim \mathcal{N}(0, I)$</span> is Gaussian noise and <span>$\sigma$</span> controls the step size.</p><p>Each proposal is accepted with probability:</p><p class="math-container">\[\alpha = \min\left(1, \frac{\pi(\theta_{\text{prop}} | \mathcal{D})}{\pi(\theta_{\text{current}} | \mathcal{D})} \times \frac{q(\theta_{\text{current}} | \theta_{\text{prop}})}{q(\theta_{\text{prop}} | \theta_{\text{current}})}\right)\]</p><p>where <span>$q(\theta&#39; | \theta)$</span> is the proposal distribution probability density for transitioning from state <span>$\theta$</span> to <span>$\theta&#39;$</span>. In MALA, this follows a multivariate Gaussian distribution centered at the gradient-adjusted current state. The ratio <span>$\frac{q(\theta_{\text{current}} | \theta_{\text{prop}})}{q(\theta_{\text{prop}} | \theta_{\text{current}})}$</span> corrects for the asymmetry introduced by the gradient-based proposals, ensuring detailed balance and proper sampling from the posterior.</p><p><strong>Implementation Features</strong>:</p><ol><li><strong>Adaptive Step Size</strong>: The algorithm adjusts <span>$\sigma$</span> to target 57.4% acceptance rate</li><li><strong>Constraint Handling</strong>: Proposals leading to non-positive matrices are rejected</li><li><strong>Warm-up Phase</strong>: Initial burn-in period for chain convergence</li></ol><h2 id="Computational-Cost"><a class="docs-heading-anchor" href="#Computational-Cost">Computational Cost</a><a id="Computational-Cost-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Cost" title="Permalink"></a></h2><p><strong>Warning</strong>: Bayesian inference is computationally expensive, requiring orders of magnitude more time than linear inversion or MLE. Typical runs require thousands of MCMC samples, each involving gradient computations and matrix operations. This method should be used when uncertainty quantification justifies the computational overhead.</p><h2 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h2><pre><code class="language-julia hljs">method = BayesianInference()

ρ_est, θ_est, Σ = estimate_state(outcomes, μ, method; 
                                 nsamples=10000,                    # Posterior samples
                                 nwarm=1000,                        # Warm-up iterations
                                 σ=1e-2,                           # Initial step size
                                 log_prior=θ -&gt; zero(eltype(θ)))    # Prior function</code></pre><p><strong>Parameters</strong>:</p><ul><li><code>nsamples</code>: Number of MCMC samples to collect from posterior</li><li><code>nwarm</code>: Number of warm-up iterations for chain equilibration</li><li><code>σ</code>: Initial step size parameter (automatically adapted)</li><li><code>log_prior</code>: Function specifying the log-prior density</li><li><code>θ₀</code>: Initial Bloch vector (default: maximally mixed state)</li><li><code>chain</code>: Optional matrix to store the full MCMC chain</li></ul><p><strong>Output</strong>:</p><ul><li><code>ρ_est</code>: Posterior mean density matrix</li><li><code>θ_est</code>: Posterior mean Bloch vector  </li><li><code>Σ</code>: Posterior covariance matrix (uncertainty quantification)</li></ul><h2 id="When-to-Use-Bayesian-Inference"><a class="docs-heading-anchor" href="#When-to-Use-Bayesian-Inference">When to Use Bayesian Inference</a><a id="When-to-Use-Bayesian-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#When-to-Use-Bayesian-Inference" title="Permalink"></a></h2><p>Use Bayesian inference when:</p><ul><li>Uncertainty quantification is required</li><li>Working with limited data where other methods fail</li><li>Parameter correlations are important</li><li>Computational cost is acceptable relative to accuracy requirements</li></ul><p>For routine tomography or when computational speed is important, consider linear inversion or MLE instead. See <a href="../choosing_methods/#Choosing-Estimation-Methods">Choosing Estimation Methods</a> for detailed guidance.</p><h2 id="Relationship-to-Other-Methods"><a class="docs-heading-anchor" href="#Relationship-to-Other-Methods">Relationship to Other Methods</a><a id="Relationship-to-Other-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Relationship-to-Other-Methods" title="Permalink"></a></h2><p>Bayesian inference represents the most complete statistical approach:</p><ul><li><strong>vs <a href="../mathematical_foundations/#linear_inversion">Linear Inversion</a></strong>: Handles any sample size, provides uncertainty quantification</li><li><strong>vs <a href="../maximum_likelihood/#Maximum-Likelihood-Estimation">Maximum Likelihood Estimation</a></strong>: Full posterior vs point estimate, incorporates prior knowledge</li><li><strong>Cost</strong>: Significantly higher computational expense</li></ul><p>The method is recommended when the additional computational cost is justified by the need for rigorous uncertainty analysis or when working in the challenging regime of very limited experimental data.</p><h2 id="See-Also"><a class="docs-heading-anchor" href="#See-Also">See Also</a><a id="See-Also-1"></a><a class="docs-heading-anchor-permalink" href="#See-Also" title="Permalink"></a></h2><ul><li><a href="../mathematical_foundations/#Mathematical-Foundations">Mathematical Foundations</a>: Basic theory and linear inversion methods  </li><li><a href="../maximum_likelihood/#Maximum-Likelihood-Estimation">Maximum Likelihood Estimation</a>: Optimal point estimation for low counts</li><li><a href="../choosing_methods/#Choosing-Estimation-Methods">Choosing Estimation Methods</a>: Practical guide for method selection</li><li><a href="../random_states/#random_states">Random States</a>: Generating test data for validation</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../maximum_likelihood/">« Maximum Likelihood Estimation</a><a class="docs-footer-nextpage" href="../proportional_measurements/">Proportional Measurements »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Sunday 20 July 2025 19:01">Sunday 20 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
